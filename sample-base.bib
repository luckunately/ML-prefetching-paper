
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries
@misc{zswap-1,
author = {},
title = {zswap — The Linux Kernel documentation},
url = {https://www.kernel.org/doc/html/v4.18/vm/zswap.html},
year = {2008},
}

@misc{frontswap,
author = {},
title = {Frontswap — The Linux Kernel documentation},
howpublished = {\url{https://docs.kernel.org/vm/frontswap.html}},
month = {},
year = {2008},
note = {(Accessed on 03/17/2022)}
}


@inproceedings{google,
title	= {Software-defined far memory in warehouse-scale computers},
author	= {Andres Lagar-Cavilla and Junwhan Ahn and Suleiman Souhlal and Neha Agarwal and Radoslaw Burny and Shakeel Butt and Jichuan Chang and Ashwin Chaugule and Nan Deng and Junaid Shahid and Greg Thelen and Kamil Adam Yurtsever and Yu Zhao and Parthasarathy Ranganathan},
year	= {2019},
URL	= {http://doi.acm.org/10.1145/3297858.3304053},
booktitle	= {International Conference on Architectural Support for Programming Languages and Operating Systems}
}

@inproceedings{meta,
author = {Weiner, Johannes and Agarwal, Niket and Schatzberg, Dan and Yang, Leon and Wang, Hao and Sanouillet, Blaise and Sharma, Bikash and Heo, Tejun and Jain, Mayank and Tang, Chunqiang and Skarlatos, Dimitrios},
title = {TMO: Transparent Memory Offloading in Datacenters},
year = {2022},
isbn = {9781450392051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503222.3507731},
doi = {10.1145/3503222.3507731},
booktitle = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {609–621},
numpages = {13},
keywords = {Operating Systems, Datacenters, Non-volatile Memory, Memory Management},
location = {Lausanne, Switzerland},
series = {ASPLOS 2022}
}

@inproceedings {PIM,
author = {Joel Nider and Craig Mustard and Andrada Zoltan and John Ramsden and Larry Liu and Jacob Grossbard and Mohammad Dashti and Romaric Jodin and Alexandre Ghiti and Jordi Chauzi and Alexandra Fedorova},
title = {A Case Study of {Processing-in-Memory} in {off-the-Shelf} Systems},
booktitle = {2021 USENIX Annual Technical Conference (USENIX ATC 21)},
year = {2021},
isbn = {978-1-939133-23-6},
pages = {117--130},
url = {https://www.usenix.org/conference/atc21/presentation/nider},
publisher = {USENIX Association},
month = jul,
}

@misc{upmem,
	title = {{UPMEM}},
	year = {2022},
	month = {Mar},
	note = {[Online; accessed 17. Mar. 2022]},
	url = {https://www.upmem.com}
}

@inproceedings{arc,
author = {Megiddo, Nimrod and Modha, Dharmendra S.},
title = {ARC: A Self-Tuning, Low Overhead Replacement Cache},
year = {2003},
publisher = {USENIX Association},
address = {USA},
abstract = {We consider the problem of cache management in a demand paging scenario with uniform page sizes. We propose a new cache management policy, namely, Adaptive Replacement Cache (ARC), that has several advantages.In response to evolving and changing access patterns, ARC dynamically, adaptively, and continually balances between the recency and frequency components in an online and self-tuning fashion. The policy ARC uses a learning rule to adaptively and continually revise its assumptions about the workload.The policy ARC is empirically universal, that is, it empirically performs as well as a certain fixed replacement policy-even when the latter uses the best workload-specific tuning parameter that was selected in an offline fashion. Consequently, ARC works uniformly well across varied workloads and cache sizes without any need for workload specific a priori knowledge or tuning. Various policies such as LRU-2, 2Q, LRFU, and LIRS require user-defined parameters, and, unfortunately, no single choice works uniformly well across different workloads and cache sizes.The policy ARC is simple-to-implement and, like LRU, has constant complexity per request. In comparison, policies LRU-2 and LRFU both require logarithmic time complexity in the cache size.The policy ARC is scan-resistant: it allows one-time se-quential requests to pass through without polluting the cache.On 23 real-life traces drawn from numerous domains, ARC leads to substantial performance gains over LRU for a wide range of cache sizes. For example, for a SPC1 like synthetic benchmark, at 4GB cache, LRU delivers a hit ratio of 9.19% while ARC achieves a hit ratio of 20%.},
booktitle = {Proceedings of the 2nd USENIX Conference on File and Storage Technologies},
pages = {115–130},
numpages = {16},
location = {San Francisco, CA},
series = {FAST '03}
}

@INPROCEEDINGS{dram-1,
  author={Lee, Seok-Hee},
  booktitle={2016 IEEE International Electron Devices Meeting (IEDM)}, 
  title={Technology scaling challenges and opportunities of memory devices}, 
  year={2016},
  volume={},
  number={},
  pages={1.1.1-1.1.8},
  doi={10.1109/IEDM.2016.7838026}}
  
  @ARTICLE{dram-2,
  author={Mack, Chris A.},
  journal={IEEE Transactions on Semiconductor Manufacturing}, 
  title={Fifty Years of Moore's Law}, 
  year={2011},
  volume={24},
  number={2},
  pages={202-207},
  doi={10.1109/TSM.2010.2096437}}
  
  @inproceedings{car,
author = {Bansal, Sorav and Modha, Dharmendra S.},
title = {CAR: Clock with Adaptive Replacement},
year = {2004},
publisher = {USENIX Association},
address = {USA},
abstract = {CLOCK is a classical cache replacement policy dating back to 1968 that was proposed as a low-complexity approximation to LRU. On every cache hit, the policy LRU needs to move the accessed item to the most recently used position, at which point, to ensure consistency and correctness, it serializes cache hits behind a single global lock. CLOCK eliminates this lock contention, and, hence, can support high concurrency and high throughput environments such as virtual memory (for example, Multics, UNIX, BSD, AIX) and databases (for example, DB2). Unfortunately, CLOCK is still plagued by disadvantages of LRU such as disregard for "frequency", susceptibility to scans, and low performance.As our main contribution, we propose a simple and elegant new algorithm, namely, CLOCK with Adaptive Replacement (CAR), that has several advantages over CLOCK: (i) it is scan-resistant; (ii) it is self-tuning and it adaptively and dynamically captures the "recency" and "frequency" features of a workload; (iii) it uses essentially the same primitives as CLOCK, and, hence, is low-complexity and amenable to a high-concurrency implementation; and (iv) it outperforms CLOCK across a wide-range of cache sizes and workloads. The algorithm CAR is inspired by the Adaptive Replacement Cache (ARC) algorithm, and inherits virtually all advantages of ARC including its high performance, but does not serialize cache hits behind a single global lock. As our second contribution, we introduce another novel algorithm, namely, CAR with Temporal filtering (CART), that has all the advantages of CAR, but, in addition, uses a certain temporal filter to distill pages with long-term utility from those with only short-term utility.},
booktitle = {Proceedings of the 3rd USENIX Conference on File and Storage Technologies},
pages = {187–200},
numpages = {14},
location = {San Francisco, CA},
series = {FAST '04}
}

@article{adaptive6,
author = {Glass, Gideon and Cao, Pei},
title = {Adaptive Page Replacement Based on Memory Reference Behavior},
year = {1997},
issue_date = {June 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/258623.258681},
doi = {10.1145/258623.258681},
abstract = {As disk performance continues to lag behind that of memory systems and processors, virtual memory management becomes increasingly important for overall system performance. In this paper we study the page reference behavior of a collection of memory-intensive applications, and propose a new virtual memory page replacement algorithm, SEQ. SEQ detects long sequences of page faults and applies most-recently-used replacement to those sequences. Simulations show that for a large class of applications, SEQ performs close to the optimal replacement algorithm, and significantly better than Least-Recently-Used (LRU). In addition, SEQ performs similarly to LRU for applications that do not exhibit sequential faulting.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {115–126},
numpages = {12}
}


@inproceedings{adaptive1,
author = {Glass, Gideon and Cao, Pei},
title = {Adaptive Page Replacement Based on Memory Reference Behavior},
year = {1997},
isbn = {0897919092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/258612.258681},
doi = {10.1145/258612.258681},
abstract = {As disk performance continues to lag behind that of memory systems and processors, virtual memory management becomes increasingly important for overall system performance. In this paper we study the page reference behavior of a collection of memory-intensive applications, and propose a new virtual memory page replacement algorithm, SEQ. SEQ detects long sequences of page faults and applies most-recently-used replacement to those sequences. Simulations show that for a large class of applications, SEQ performs close to the optimal replacement algorithm, and significantly better than Least-Recently-Used (LRU). In addition, SEQ performs similarly to LRU for applications that do not exhibit sequential faulting.},
booktitle = {Proceedings of the 1997 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {115–126},
numpages = {12},
location = {Seattle, Washington, USA},
series = {SIGMETRICS '97}
}

@inproceedings {adaptive2,
author = {Song Jiang and Feng Chen and Xiaodong Zhang},
title = {{CLOCK-Pro}: An Effective Improvement of the {CLOCK} Replacement},
booktitle = {2005 USENIX Annual Technical Conference (USENIX ATC 05)},
year = {2005},
address = {Anaheim, CA},
url = {https://www.usenix.org/conference/2005-usenix-annual-technical-conference/clock-pro-effective-improvement-clock-replacement},
publisher = {USENIX Association},
month = apr,
}

@article{adaptive3,
author = {Jiang, Song and Zhang, Xiaodong},
title = {LIRS: An Efficient Low Inter-Reference Recency Set Replacement Policy to Improve Buffer Cache Performance},
year = {2002},
issue_date = {June 2002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {0163-5999},
url = {https://doi.org/10.1145/511399.511340},
doi = {10.1145/511399.511340},
abstract = {Although LRU replacement policy has been commonly used in the buffer cache management, it is well known for its inability to cope with access patterns with weak locality. Previous work, such as LRU-K and 2Q, attempts to enhance LRU capacity by making use of additional history information of previous block references other than only the recency information used in LRU. These algorithms greatly increase complexity and/or can not consistently provide performance improvement. Many recently proposed policies, such as UBM and SEQ, improve replacement performance by exploiting access regularities in references. They only address LRU problems on certain specific and well-defined cases such as access patterns like sequences and loops. Motivated by the limits of previous studies, we propose an efficient buffer cache replacement policy, called Low Inter-reference Recency Set (LIRS). LIRS effectively addresses the limits of LRU by using recency to evaluate Inter-Reference Recency (IRR) for making a replacement decision. This is in contrast to what LRU does: directly using recency to predict next reference timing. At the same time, LIRS almost retains the same simple assumption of LRU to predict future access behavior of blocks. Our objectives are to effectively address the limits of LRU for a general purpose, to retain the low overhead merit of LRU, and to outperform those replacement policies relying on the access regularity detections. Conducting simulations with a variety of traces and a wide range of cache sizes, we show that LIRS significantly outperforms LRU, and outperforms other existing replacement algorithms in most cases. Furthermore, we show that the additional cost for implementing LIRS is trivial in comparison with LRU.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jun},
pages = {31–42},
numpages = {12}
}


@inproceedings{adaptive4,
author = {Jiang, Song and Zhang, Xiaodong},
title = {LIRS: An Efficient Low Inter-Reference Recency Set Replacement Policy to Improve Buffer Cache Performance},
year = {2002},
isbn = {1581135319},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/511334.511340},
doi = {10.1145/511334.511340},
abstract = {Although LRU replacement policy has been commonly used in the buffer cache management, it is well known for its inability to cope with access patterns with weak locality. Previous work, such as LRU-K and 2Q, attempts to enhance LRU capacity by making use of additional history information of previous block references other than only the recency information used in LRU. These algorithms greatly increase complexity and/or can not consistently provide performance improvement. Many recently proposed policies, such as UBM and SEQ, improve replacement performance by exploiting access regularities in references. They only address LRU problems on certain specific and well-defined cases such as access patterns like sequences and loops. Motivated by the limits of previous studies, we propose an efficient buffer cache replacement policy, called Low Inter-reference Recency Set (LIRS). LIRS effectively addresses the limits of LRU by using recency to evaluate Inter-Reference Recency (IRR) for making a replacement decision. This is in contrast to what LRU does: directly using recency to predict next reference timing. At the same time, LIRS almost retains the same simple assumption of LRU to predict future access behavior of blocks. Our objectives are to effectively address the limits of LRU for a general purpose, to retain the low overhead merit of LRU, and to outperform those replacement policies relying on the access regularity detections. Conducting simulations with a variety of traces and a wide range of cache sizes, we show that LIRS significantly outperforms LRU, and outperforms other existing replacement algorithms in most cases. Furthermore, we show that the additional cost for implementing LIRS is trivial in comparison with LRU.},
booktitle = {Proceedings of the 2002 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {31–42},
numpages = {12},
location = {Marina Del Rey, California},
series = {SIGMETRICS '02}
}

@inproceedings{adaptive5,
author = {Johnson, Theodore and Shasha, Dennis},
title = {2Q: A Low Overhead High Performance Buffer Management Replacement Algorithm},
year = {1994},
isbn = {1558601538},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the 20th International Conference on Very Large Data Bases},
pages = {439–450},
numpages = {12},
series = {VLDB '94}
}

@inproceedings{path,
author = {Azimi, Reza and Soares, Livio and Stumm, Michael and Walsh, Thomas and Brown, Angela Demke},
title = {Path: Page Access Tracking to Improve Memory Management},
year = {2007},
isbn = {9781595938930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1296907.1296914},
doi = {10.1145/1296907.1296914},
abstract = {Traditionally, operating systems use a coarse approximation of memory accesses to implement memory management algorithms by monitoring page faults or scanning page table entries. With finer-grained memory access information, however, the operating system can manage memory muchmore effectively. Previous work has proposed the use of a software mechanism based on virtual page protection and soft faults to track page accesses at finer granularity. In this paper, we show that while this approach is effective for some applications, for many others it results in an unacceptably high overhead. We propose simple Page Access Tracking Hardware (PATH)to provide accurate page access information to the operating system. The suggested hardware support is generic andcan be used by various memory management algorithms. In this paper, we show how the information generated by PATH can be used to implement (i) adaptive page replacement policies, (ii) smart process memory allocation to improve performance or to provide isolation and better process prioritization, and (iii) effectively prefetch virtual memory pages when applications have non-trivial memory access patterns. Our simulation results show that these algorithms can dramatically improve performance (up to 500%) with PATH-provided information, especially when the system is under memory pressure. We show that the software overhead of processing PATH information is less than 6% acrossthe applications we examined (less than 3% in all but two applications), which is at least an order of magni.},
booktitle = {Proceedings of the 6th International Symposium on Memory Management},
pages = {31–42},
numpages = {12},
keywords = {page access tracking, page re-, translation lookaside buffer},
location = {Montreal, Quebec, Canada},
series = {ISMM '07}
}

@inproceedings{leap,
author = {Al Maruf, Hasan and Chowdhury, Mosharaf},
title = {Effectively Prefetching Remote Memory with Leap},
year = {2020},
isbn = {978-1-939133-14-4},
publisher = {USENIX Association},
address = {USA},
abstract = {Memory disaggregation over RDMA can improve the performance of memory-constrained applications by replacing disk swapping with remote memory accesses. However, state-of-the-art memory disaggregation solutions still use data path components designed for slow disks. As a result, applications experience remote memory access latency significantly higher than that of the underlying low-latency network, which itself can be too high for many applications.In this paper, we propose Leap, a prefetching solution for remote memory accesses due to memory disaggregation. At its core, Leap employs an online, majority-based prefetching algorithm, which increases the page cache hit rate. We complement it with a lightweight and efficient data path in the kernel that isolates each application's data path to the disaggregated memory and mitigates latency bottlenecks arising from legacy throughput-optimizing operations. Integration of Leap in the Linux kernel improves the median and tail remote page access latencies of memory-bound applications by up to 104.04\texttimes{} and 22.62\texttimes{}, respectively, over the default data path. This leads to up to 10.16\texttimes{} performance improvements for applications using disaggregated memory in comparison to the state-of-the-art solutions.},
booktitle = {Proceedings of the 2020 USENIX Conference on Usenix Annual Technical Conference},
articleno = {58},
numpages = {15},
series = {USENIX ATC'20}
}

@online{vma-readahead,
 author = {Linux kernel},
  title = {{Linux Kernel} VMA readahead prefetcher},
  year = 2017,
  url = {https://lwn.net/Articles/716296/},
  urldate = {2017-05-06}
}

@inproceedings{fastswap,
author = {Amaro, Emmanuel and Branner-Augmon, Christopher and Luo, Zhihong and Ousterhout, Amy and Aguilera, Marcos K. and Panda, Aurojit and Ratnasamy, Sylvia and Shenker, Scott},
title = {Can Far Memory Improve Job Throughput?},
year = {2020},
isbn = {9781450368827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342195.3387522},
doi = {10.1145/3342195.3387522},
abstract = {As memory requirements grow, and advances in memory technology slow, the availability of sufficient main memory is increasingly the bottleneck in large compute clusters. One solution to this is memory disaggregation, where jobs can remotely access memory on other servers, or far memory. This paper first presents faster swapping mechanisms and a far memory-aware cluster scheduler that make it possible to support far memory at rack scale. Then, it examines the conditions under which this use of far memory can increase job throughput. We find that while far memory is not a panacea, for memory-intensive workloads it can provide performance improvements on the order of 10% or more even without changing the total amount of memory available.},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
articleno = {14},
numpages = {16},
location = {Heraklion, Greece},
series = {EuroSys '20}
}
@inproceedings {infiniswap,
author = {Juncheng Gu and Youngmoon Lee and Yiwen Zhang and Mosharaf Chowdhury and Kang G. Shin},
title = {Efficient Memory Disaggregation with Infiniswap},
booktitle = {14th USENIX Symposium on Networked Systems Design and Implementation (NSDI 17)},
year = {2017},
isbn = {978-1-931971-37-9},
address = {Boston, MA},
pages = {649--667},
url = {https://www.usenix.org/conference/nsdi17/technical-sessions/presentation/gu},
publisher = {USENIX Association},
month = mar,
}

@misc{canvas,
  doi = {10.48550/ARXIV.2203.09615},
  
  url = {https://arxiv.org/abs/2203.09615},
  
  author = {Wang, Chenxi and Qiao, Yifan and Ma, Haoran and Liu, Shi and Zhang, Yiying and Chen, Wenguang and Netravali, Ravi and Kim, Miryung and Xu, Guoqing Harry},
  
  keywords = {Operating Systems (cs.OS), Distributed, Parallel, and Cluster Computing (cs.DC), Networking and Internet Architecture (cs.NI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Canvas: Isolated and Adaptive Swapping for Multi-Applications on Remote Memory},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings {memliner,
author = {Chenxi Wang and Haoran Ma and Shi Liu and Yifan Qiao and Jonathan Eyolfson and Christian Navasca and Shan Lu and Guoqing Harry Xu},
title = {{MemLiner}: Lining up Tracing and Application for a {Far-Memory-Friendly} Runtime},
booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},
year = {2022},
isbn = {978-1-939133-28-1},
address = {Carlsbad, CA},
pages = {35--53},
url = {https://www.usenix.org/conference/osdi22/presentation/wang},
publisher = {USENIX Association},
month = jul,
}

@inproceedings{classifying,
author = {Ayers, Grant and Litz, Heiner and Kozyrakis, Christos and Ranganathan, Parthasarathy},
title = {Classifying Memory Access Patterns for Prefetching},
year = {2020},
isbn = {9781450371025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373376.3378498},
doi = {10.1145/3373376.3378498},
abstract = {Prefetching is a well-studied technique for addressing the memory access stall time of contemporary microprocessors. However, despite a large body of related work, the memory access behavior of applications is not well understood, and it remains difficult to predict whether a particular application will benefit from a given prefetcher technique. In this work we propose a novel methodology to classify the memory access patterns of applications, enabling well-informed reasoning about the applicability of a certain prefetcher. Our approach leverages instruction dataflow information to uncover a wide range of access patterns, including arbitrary combinations of offsets and indirection. These combinations or prefetch kernels represent reuse, strides, reference locality, and complex address generation. By determining the complexity and frequency of these access patterns, we enable reasoning about prefetcher timeliness and criticality, exposing the limitations of existing prefetchers today. Moreover, using these kernels, we are able to compute the next address for the majority of top-missing instructions, and we propose a software prefetch injection methodology that is able to outperform state-of-the-art hardware prefetchers.},
booktitle = {Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {513–526},
numpages = {14},
keywords = {memory access patterns, dataflow, classification, wsc, warehouse-scale computers, prefetching, prefetcher},
location = {Lausanne, Switzerland},
series = {ASPLOS '20}
}
@inproceedings{10.1145/3037697.3037706,
author = {Agarwal, Neha and Wenisch, Thomas F.},
title = {Thermostat: Application-Transparent Page Management for Two-Tiered Main Memory},
year = {2017},
isbn = {9781450344654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3037697.3037706},
doi = {10.1145/3037697.3037706},
abstract = {The advent of new memory technologies that are denser and cheaper than commodity DRAM has renewed interest in two-tiered main memory schemes. Infrequently accessed application data can be stored in such memories to achieve significant memory cost savings. Past research on two-tiered main memory has assumed a 4KB page size. However, 2MB huge pages are performance critical in cloud applications with large memory footprints, especially in virtualized cloud environments, where nested paging drastically increases the cost of 4KB page management. We present Thermostat, an application-transparent huge-page-aware mechanism to place pages in a dual-technology hybrid memory system while achieving both the cost advantages of two-tiered memory and performance advantages of transparent huge pages. We present an online page classification mechanism that accurately classifies both 4KB and 2MB pages as hot or cold while incurring no observable performance overhead across several representative cloud applications. We implement Thermostat in Linux kernel version 4.5 and evaluate its effectiveness on representative cloud computing workloads running under KVM virtualization. We emulate slow memory with performance characteristics approximating near-future high-density memory technology and show that Thermostat migrates up to 50% of application footprint to slow memory while limiting performance degradation to 3%, thereby reducing memory cost up to 30%.},
booktitle = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {631–644},
numpages = {14},
keywords = {cloud computing, operating systems},
location = {Xi'an, China},
series = {ASPLOS '17}
}


@article{10.1145/3093337.3037706,
author = {Agarwal, Neha and Wenisch, Thomas F.},
title = {Thermostat: Application-Transparent Page Management for Two-Tiered Main Memory},
year = {2017},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5964},
url = {https://doi.org/10.1145/3093337.3037706},
doi = {10.1145/3093337.3037706},
abstract = {The advent of new memory technologies that are denser and cheaper than commodity DRAM has renewed interest in two-tiered main memory schemes. Infrequently accessed application data can be stored in such memories to achieve significant memory cost savings. Past research on two-tiered main memory has assumed a 4KB page size. However, 2MB huge pages are performance critical in cloud applications with large memory footprints, especially in virtualized cloud environments, where nested paging drastically increases the cost of 4KB page management. We present Thermostat, an application-transparent huge-page-aware mechanism to place pages in a dual-technology hybrid memory system while achieving both the cost advantages of two-tiered memory and performance advantages of transparent huge pages. We present an online page classification mechanism that accurately classifies both 4KB and 2MB pages as hot or cold while incurring no observable performance overhead across several representative cloud applications. We implement Thermostat in Linux kernel version 4.5 and evaluate its effectiveness on representative cloud computing workloads running under KVM virtualization. We emulate slow memory with performance characteristics approximating near-future high-density memory technology and show that Thermostat migrates up to 50% of application footprint to slow memory while limiting performance degradation to 3%, thereby reducing memory cost up to 30%.},
journal = {SIGARCH Comput. Archit. News},
month = {apr},
pages = {631–644},
numpages = {14},
keywords = {cloud computing, operating systems}
}


@article{thermostat,
author = {Agarwal, Neha and Wenisch, Thomas F.},
title = {Thermostat: Application-Transparent Page Management for Two-Tiered Main Memory},
year = {2017},
issue_date = {April 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/3093336.3037706},
doi = {10.1145/3093336.3037706},
journal = {SIGPLAN Not.},
month = {apr},
pages = {631–644},
numpages = {14},
keywords = {operating systems, cloud computing}
}

@inproceedings{dilos,
author = {Yoon, Wonsup and Oh, Jinyoung and Ok, Jisu and Moon, Sue and Kwon, Youngjin},
title = {DiLOS: Adding Performance to Paging-Based Memory Disaggregation},
year = {2021},
isbn = {9781450386982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3476886.3477507},
doi = {10.1145/3476886.3477507},
booktitle = {Proceedings of the 12th ACM SIGOPS Asia-Pacific Workshop on Systems},
pages = {70–78},
numpages = {9},
keywords = {disaggregated data center, unikernel, memory disaggregation},
location = {Hong Kong, China},
series = {APSys '21}
}

@inproceedings {aifm,
author = {Zhenyuan Ruan and Malte Schwarzkopf and Marcos K. Aguilera and Adam Belay},
title = {{AIFM}: {High-Performance}, {Application-Integrated} Far Memory},
booktitle = {14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20)},
year = {2020},
isbn = {978-1-939133-19-9},
pages = {315--332},
url = {https://www.usenix.org/conference/osdi20/presentation/ruan},
publisher = {USENIX Association},
month = nov,
}

@inproceedings {znswap,
author = {Shai Bergman and Niklas Cassel and Matias Bj{\o}rling and Mark Silberstein},
title = {{ZNSwap}: {un-Block} your Swap},
booktitle = {2022 USENIX Annual Technical Conference (USENIX ATC 22)},
year = {2022},
isbn = {978-1-939133-29-12},
address = {Carlsbad, CA},
pages = {1--18},
url = {https://www.usenix.org/conference/atc22/presentation/bergman},
publisher = {USENIX Association},
month = jul,
}


@inproceedings {hopp,
author = {Haifeng Li,Ke Liu,Ting Liang, Zuojun Li, Tianyue Lu, Hui Yuan,Yinben Xia,Yungang Bao,Mingyu Chen,Yizhou Shan},
title = {HoPP: Hardware-Software Co-Designed Page
Prefetching for Disaggregated Memory},
booktitle = {HPCA'23},
year = {2023},
url = {http://lastweek.io/pubs/HoPP-HPCA23.pdf},
publisher = {IEEE Association},
}

@inproceedings{hemem,
author = {Raybuck, Amanda and Stamler, Tim and Zhang, Wei and Erez, Mattan and Peter, Simon},
title = {HeMem: Scalable Tiered Memory Management for Big Data Applications and Real NVM},
year = {2021},
isbn = {9781450387095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477132.3483550},
doi = {10.1145/3477132.3483550},
abstract = {},
booktitle = {Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles},
pages = {392–407},
numpages = {16},
keywords = {Operating system, Tiered memory management, Scalability},
location = {Virtual Event, Germany},
series = {SOSP '21}
}

@article{10.1145/2678373.2665740,
author = {Woodruff, Jonathan and Watson, Robert N.M. and Chisnall, David and Moore, Simon W. and Anderson, Jonathan and Davis, Brooks and Laurie, Ben and Neumann, Peter G. and Norton, Robert and Roe, Michael},
title = {The CHERI Capability Model: Revisiting RISC in an Age of Risk},
year = {2014},
issue_date = {June 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {3},
issn = {0163-5964},
url = {https://doi.org/10.1145/2678373.2665740},
doi = {10.1145/2678373.2665740},
abstract = {Motivated by contemporary security challenges, we reevaluate and refine capability-based addressing for the RISC era. We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection. We demonstrate that CHERI enables language memory model enforcement and fault isolation in hardware rather than software, and that the CHERI mechanisms are easily adopted by existing programs for efficient in-program memory safety. In contrast to past capability models, CHERI complements, rather than replaces, the ubiquitous page-based protection mechanism, providing a migration path towards deconflating data-structure protection and OS memory management. Furthermore, CHERI adheres to a strict RISC philosophy: it maintains a load-store architecture and requires only singlecycle instructions, and supplies protection primitives to the compiler, language runtime, and operating system. We demonstrate a mature FPGA implementation that runs the FreeBSD operating system with a full range of software and an open-source application suite compiled with an extended LLVM to use CHERI memory protection. A limit study compares published memory safety mechanisms in terms of instruction count and memory overheads. The study illustrates that CHERI is performance-competitive even while providing assurance and greater flexibility with simpler hardware},
journal = {SIGARCH Comput. Archit. News},
month = {jun},
pages = {457–468},
numpages = {12}
}

@inproceedings{cheri,
author = {Woodruff, Jonathan and Watson, Robert N.M. and Chisnall, David and Moore, Simon W. and Anderson, Jonathan and Davis, Brooks and Laurie, Ben and Neumann, Peter G. and Norton, Robert and Roe, Michael},
title = {The CHERI Capability Model: Revisiting RISC in an Age of Risk},
year = {2014},
isbn = {9781479943944},
publisher = {IEEE Press},
abstract = {Motivated by contemporary security challenges, we reevaluate and refine capability-based addressing for the RISC era. We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection. We demonstrate that CHERI enables language memory model enforcement and fault isolation in hardware rather than software, and that the CHERI mechanisms are easily adopted by existing programs for efficient in-program memory safety. In contrast to past capability models, CHERI complements, rather than replaces, the ubiquitous page-based protection mechanism, providing a migration path towards deconflating data-structure protection and OS memory management. Furthermore, CHERI adheres to a strict RISC philosophy: it maintains a load-store architecture and requires only singlecycle instructions, and supplies protection primitives to the compiler, language runtime, and operating system. We demonstrate a mature FPGA implementation that runs the FreeBSD operating system with a full range of software and an open-source application suite compiled with an extended LLVM to use CHERI memory protection. A limit study compares published memory safety mechanisms in terms of instruction count and memory overheads. The study illustrates that CHERI is performance-competitive even while providing assurance and greater flexibility with simpler hardware},
booktitle = {Proceeding of the 41st Annual International Symposium on Computer Architecuture},
pages = {457–468},
numpages = {12},
location = {Minneapolis, Minnesota, USA},
series = {ISCA '14}
}

@INPROCEEDINGS{cache-analysis,
  author={Karlsson, M. and Dahlgren, F. and Stenstrom, P.},
  booktitle={Proceedings Sixth International Symposium on High-Performance Computer Architecture. HPCA-6 (Cat. No.PR00550)}, 
  title={A prefetching technique for irregular accesses to linked data structures}, 
  year={2000},
  volume={},
  number={},
  pages={206-217},
  doi={10.1109/HPCA.2000.824351}}

@inproceedings{cheribsd,
author = {Davis, Brooks and Watson, Robert N. M. and Richardson, Alexander and Neumann, Peter G. and Moore, Simon W. and Baldwin, John and Chisnall, David and Clarke, Jessica and Filardo, Nathaniel Wesley and Gudka, Khilan and Joannou, Alexandre and Laurie, Ben and Markettos, A. Theodore and Maste, J. Edward and Mazzinghi, Alfredo and Napierala, Edward Tomasz and Norton, Robert M. and Roe, Michael and Sewell, Peter and Son, Stacey and Woodruff, Jonathan},
title = {CheriABI: Enforcing Valid Pointer Provenance and Minimizing Pointer Privilege in the POSIX C Run-Time Environment},
year = {2019},
isbn = {9781450362405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297858.3304042},
doi = {10.1145/3297858.3304042},
abstract = {The CHERI architecture allows pointers to be implemented as capabilities (rather than integer virtual addresses) in a manner that is compatible with, and strengthens, the semantics of the C language. In addition to the spatial protections offered by conventional fat pointers, CHERI capabilities offer strong integrity, enforced provenance validity, and access monotonicity. The stronger guarantees of these architectural capabilities must be reconciled with the real-world behavior of operating systems, run-time environments, and applications. When the process model, user-kernel interactions, dynamic linking, and memory management are all considered, we observe that simple derivation of architectural capabilities is insufficient to describe appropriate access to memory. We bridge this conceptual gap with a notional abstract capability that describes the accesses that should be allowed at a given point in execution, whether in the kernel or userspace. To investigate this notion at scale, we describe the first adaptation of a full C-language operating system (FreeBSD) with an enterprise database (PostgreSQL) for complete spatial and referential memory safety. We show that awareness of abstract capabilities, coupled with CHERI architectural capabilities, can provide more complete protection, strong compatibility, and acceptable performance overhead compared with the pre-CHERI baseline and software-only approaches. Our observations also have potentially significant implications for other mitigation techniques.},
booktitle = {Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {379–393},
numpages = {15},
keywords = {security, operating systems, hardware, cheri},
location = {Providence, RI, USA},
series = {ASPLOS '19}
}

@phdthesis{parsec,
  author = {Christian Bienia},
  title = {Benchmarking Modern Multiprocessors},
  school = {Princeton University},
  year      = {2011},
  month     = {January}
}

@inproceedings{pin,
author = {Luk, Chi-Keung and Cohn, Robert and Muth, Robert and Patil, Harish and Klauser, Artur and Lowney, Geoff and Wallace, Steven and Reddi, Vijay Janapa and Hazelwood, Kim},
title = {Pin: Building Customized Program Analysis Tools with Dynamic Instrumentation},
year = {2005},
isbn = {1595930566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1065010.1065034},
doi = {10.1145/1065010.1065034},
booktitle = {Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {190–200},
numpages = {11},
keywords = {instrumentation, program analysis tools, dynamic compilation},
location = {Chicago, IL, USA},
series = {PLDI '05}
}


@INPROCEEDINGS{cornucopia,
  author={Wesley Filardo, Nathaniel and Gutstein, Brett F. and Woodruff, Jonathan and Ainsworth, Sam and Paul-Trifu, Lucian and Davis, Brooks and Xia, Hongyan and Tomasz Napierala, Edward and Richardson, Alexander and Baldwin, John and Chisnall, David and Clarke, Jessica and Gudka, Khilan and Joannou, Alexandre and Theodore Markettos, A. and Mazzinghi, Alfredo and Norton, Robert M. and Roe, Michael and Sewell, Peter and Son, Stacey and Jones, Timothy M. and Moore, Simon W. and Neumann, Peter G. and Watson, Robert N. M.},
  booktitle={2020 IEEE Symposium on Security and Privacy (SP)}, 
  title={Cornucopia: Temporal Safety for CHERI Heaps}, 
  year={2020},
  volume={},
  number={},
  pages={608-625},
  doi={10.1109/SP40000.2020.00098}}

@inproceedings{cherivoke,
author = {Xia, Hongyan and Woodruff, Jonathan and Ainsworth, Sam and Filardo, Nathaniel W. and Roe, Michael and Richardson, Alexander and Rugg, Peter and Neumann, Peter G. and Moore, Simon W. and Watson, Robert N. M. and Jones, Timothy M.},
title = {CHERIvoke: Characterising Pointer Revocation Using CHERI Capabilities for Temporal Memory Safety},
year = {2019},
isbn = {9781450369381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352460.3358288},
doi = {10.1145/3352460.3358288},
abstract = {A lack of temporal safety in low-level languages has led to an epidemic of use-after-free exploits. These have surpassed in number and severity even the infamous buffer-overflow exploits violating spatial safety. Capability addressing can directly enforce spatial safety for the C language by enforcing bounds on pointers and by rendering pointers unforgeable. Nevertheless, an efficient solution for strong temporal memory safety remains elusive.CHERI is an architectural extension to provide hardware capability addressing that is seeing significant commercial and open-source interest. We show that CHERI capabilities can be used as a foundation to enable low-cost heap temporal safety by facilitating out-of-date pointer revocation, as capabilities enable precise and efficient identification and invalidation of pointers, even when using unsafe languages such as C. We develop CHERIvoke, a technique for deterministic and fast sweeping revocation to enforce temporal safety on CHERI systems. CHERIvoke quarantines freed data before periodically using a small shadow map to revoke all dangling pointers in a single sweep of memory, and provides a tunable trade-off between performance and heap growth. We evaluate the performance of such a system using high-performance x86 processors, and further analytically examine its primary overheads. When configured with a heap-size overhead of 25\%, we find that CHERIvoke achieves an average execution-time overhead of under 5\%, far below the overheads associated with traditional garbage collection, revocation, or page-table systems.},
booktitle = {Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {545–557},
numpages = {13},
keywords = {use-after-free, architecture, temporal safety, security},
location = {Columbus, OH, USA},
series = {MICRO '52}
}
 @misc{perf-probe,
 title = { Linux perf probe},
author={},
year={2000}, 
url={https://man7.org/linux/man-pages/man1/perf-probe.1.html}
} 

@article{hpcg,
    author = {Dongarra, Jack and Heroux, Michael A. and Luszczek, Piotr},
    title = "{A new metric for ranking high-performance computing systems}",
    journal = {National Science Review},
    volume = {3},
    number = {1},
    pages = {30-35},
    year = {2016},
    month = {01},
    issn = {2095-5138},
    doi = {10.1093/nsr/nwv084},
    url = {https://doi.org/10.1093/nsr/nwv084},
    eprint = {https://academic.oup.com/nsr/article-pdf/3/1/30/31565532/nwv084.pdf},
}


@article{gapbs,
  author       = {Scott Beamer and
                  Krste Asanovic and
                  David A. Patterson},
  title        = {The {GAP} Benchmark Suite},
  journal      = {CoRR},
  volume       = {abs/1508.03619},
  year         = {2015},
  url          = {http://arxiv.org/abs/1508.03619},
  eprinttype    = {arXiv},
  eprint       = {1508.03619},
  timestamp    = {Thu, 13 Apr 2023 19:55:40 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/BeamerAP15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{twitter-dataset,
author = {Kwak, Haewoon and Lee, Changhyun and Park, Hosung and Moon, Sue},
title = {What is Twitter, a Social Network or a News Media?},
year = {2010},
isbn = {9781605587998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1772690.1772751},
doi = {10.1145/1772690.1772751},
pages = {591–600},
numpages = {10},
keywords = {pagerank, online social network, homophily, information diffusion, influential, degree of separation, Twitter, retweet, reciprocity},
location = {Raleigh, North Carolina, USA},
series = {WWW '10}
}

@TechReport{cheri_prog_guide,
  author =	 {Watson, Robert N. M. and Richardson, Alexander and Davis,
          	  Brooks and Baldwin, John and Chisnall, David and Clarke,
          	  Jessica and Filardo, Nathaniel and Moore, Simon W. and
          	  Napierala, Edward and Sewell, Peter and Neumann, Peter G.},
  title = 	 {{CHERI C/C++ Programming Guide}},
  year = 	 2020,
  month = 	 jun,
  url = 	 {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-947.pdf},
  institution =  {University of Cambridge, Computer Laboratory},
  doi = 	 {10.48456/tr-947},
  number = 	 {UCAM-CL-TR-947}
}

@techreport{cheri-technical-manual,
  title={An introduction to CHERI},
  author={Watson, Robert NM and Moore, Simon W and Sewell, Peter and Neumann, Peter G},
  year={2019},
  institution={University of Cambridge, Computer Laboratory}
}

@inproceedings{10.1145/237090.237190,
author = {Luk, Chi-Keung and Mowry, Todd C.},
title = {Compiler-Based Prefetching for Recursive Data Structures},
year = {1996},
isbn = {0897917677},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/237090.237190},
doi = {10.1145/237090.237190},
abstract = {Software-controlled data prefetching offers the potential for bridging the ever-increasing speed gap between the memory subsystem and today's high-performance processors. While prefetching has enjoyed considerable success in array-based numeric codes, its potential in pointer-based applications has remained largely unexplored. This paper investigates compiler-based prefetching for pointer-based applications---in particular, those containing recursive data structures. We identify the fundamental problem in prefetching pointer-based data structures and propose a guideline for devising successful prefetching schemes. Based on this guideline, we design three prefetching schemes, we automate the most widely applicable scheme (greedy prefetching) in an optimizing research compiler, and we evaluate the performance of all three schemes on a modern superscalar processor similar to the MIPS R10000. Our results demonstrate that compiler-inserted prefetching can significantly improve the execution speed of pointer-based codes---as much as 45% for the applications we study. In addition, the more sophisticated algorithms (which we currently perform by hand, but which might be implemented in future compilers) can improve performance by as much as twofold. Compared with the only other compiler-based pointer prefetching scheme in the literature, our algorithms offer substantially better performance by avoiding unnecessary overhead and hiding more latency.},
booktitle = {Proceedings of the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {222–233},
numpages = {12},
location = {Cambridge, Massachusetts, USA},
series = {ASPLOS VII}
}


@article{10.1145/248208.237190,
author = {Luk, Chi-Keung and Mowry, Todd C.},
title = {Compiler-Based Prefetching for Recursive Data Structures},
year = {1996},
issue_date = {Dec. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {5},
issn = {0163-5980},
url = {https://doi.org/10.1145/248208.237190},
doi = {10.1145/248208.237190},
abstract = {Software-controlled data prefetching offers the potential for bridging the ever-increasing speed gap between the memory subsystem and today's high-performance processors. While prefetching has enjoyed considerable success in array-based numeric codes, its potential in pointer-based applications has remained largely unexplored. This paper investigates compiler-based prefetching for pointer-based applications---in particular, those containing recursive data structures. We identify the fundamental problem in prefetching pointer-based data structures and propose a guideline for devising successful prefetching schemes. Based on this guideline, we design three prefetching schemes, we automate the most widely applicable scheme (greedy prefetching) in an optimizing research compiler, and we evaluate the performance of all three schemes on a modern superscalar processor similar to the MIPS R10000. Our results demonstrate that compiler-inserted prefetching can significantly improve the execution speed of pointer-based codes---as much as 45% for the applications we study. In addition, the more sophisticated algorithms (which we currently perform by hand, but which might be implemented in future compilers) can improve performance by as much as twofold. Compared with the only other compiler-based pointer prefetching scheme in the literature, our algorithms offer substantially better performance by avoiding unnecessary overhead and hiding more latency.},
journal = {SIGOPS Oper. Syst. Rev.},
month = {sep},
pages = {222–233},
numpages = {12}
}

@online{cgroups,
author = {Linux},
title = {Control Group -V2},
url = {https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html},
year = {2008}
}

@online{morelloarm,
author = {ARM},
title = {Morello Program - ARM},
url = {https://www.arm.com/architecture/cpu/morello},
year = {2022}
}

@article{cache-mowry-pointer,
author = {Luk, Chi-Keung and Mowry, Todd C.},
title = {Compiler-Based Prefetching for Recursive Data Structures},
year = {1996},
issue_date = {Sept. 1996},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/248209.237190},
doi = {10.1145/248209.237190},
journal = {SIGPLAN Not.},
month = {sep},
pages = {222–233},
numpages = {12}
}

@inproceedings{wikipedie-dataset,
author = {Kunegis, J\'{e}r\^{o}me},
title = {KONECT: The Koblenz Network Collection},
year = {2013},
isbn = {9781450320382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487788.2488173},
doi = {10.1145/2487788.2488173},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {1343–1350},
numpages = {8},
keywords = {network analysis, web observatory},
location = {Rio de Janeiro, Brazil},
series = {WWW '13 Companion}
}

@online{cheri_get_tags,
title={{Swap pager}},
author= {CheriBSD},
url= {https://github.com/CTSRD-CHERI/cheribsd/blob/565ae56372dec95ac74e3cc3f5130ada41a80b05/sys/vm/swap_pager.c#L529},
year= 2023,
}

@online{vm_fault_readahead,
title={{CheriBSD prefetcher}},
author= {CheriBSD},
url= {https://github.com/CTSRD-CHERI/cheribsd/blob/565ae56372dec95ac74e3cc3f5130ada41a80b05/sys/vm/vm_fault.c#L862
},
year= 2023,
}

@online{redis,
title={{Redis | Real-time Data Platform}},
author= {Redis},
url= {https://redis.com/},
year= 2023,
}